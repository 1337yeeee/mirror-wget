# mirror-wget

Упрощённая утилита для зеркального скачивания веб-сайтов на Go, аналог `wget -m`.

## Возможности
- Скачивание HTML-страниц и всех вложенных ресурсов (CSS, JS, изображения).
- Рекурсивное скачивание страниц внутри одного домена.
- Формирование локальной структуры для оффлайн-доступа.
- Автоматическое переписывание ссылок в HTML и CSS на локальные пути.
- Параллельное скачивание с ограничением числа одновременно активных задач.
- Учёт `robots.txt`.
- Контроль глубины рекурсии.

## Установка
```bash
git clone https://github.com/yourname/mirror-wget.git
cd mirror-wget
go build -o mirror-wget main.go
```

## Использование
```bash
./mirror-wget [options] <URL>
```

## Опции
-l <N> — глубина рекурсии (по умолчанию -1, т.е. без ограничения).

## Пример
Скачать сайт с глубиной рекурсии 2:
```bash
./mirror-wget -l 2 https://example.com
```

После выполнения в текущей директории будет создана структура:
```
example.com/
├── index.html
├── css/
├── js/
├── images/
└── ...
```

Все ссылки внутри страниц будут переписаны на локальные файлы.
Структура проекта

- main.go — точка входа.
- engine/ — логика управления очередью и воркерами.
- parser/ — парсинг HTML и CSS для извлечения ссылок.
- downloader/ — скачивание ресурсов и проверка robots.txt.
- storage/ — сохранение файлов и переписывание ссылок.
- cli/ — парсинг аргументов командной строки.
- queue/ — очередь задач для воркеров.
- normalizer/ — нормализация URL.

## Технологии
- `net/http` — HTTP-клиент.
- `golang.org/x/net/html` — парсинг HTML.
- `github.com/riking/cssparse` — парсинг CSS.
- `github.com/temoto/robotstxt` — обработка robots.txt.
- конкурентность через goroutines, sync.WaitGroup, sync.Map, atomic.
